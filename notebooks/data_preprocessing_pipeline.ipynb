{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append the parent directory to sys.path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# ignore warrnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='preprocessing.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "from scripts.Data_preprocessing_pipeline import DataPreprocessingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from data_pipeline import DataPreprocessingPipeline\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='preprocessing.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading our data is in CSV format\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "store_df = pd.read_csv('../data/store.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Initialize the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline with loaded data\n",
    "pipeline = DataPreprocessingPipeline(train_df, test_df, store_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge store data\n",
    "train_merged, test_merged = pipeline.merge_store_data()\n",
    "\n",
    "# Add date features\n",
    "train_with_dates, test_with_dates = pipeline.add_date_features(train_merged, test_merged)\n",
    "\n",
    "# Handle missing data\n",
    "train_cleaned, test_cleaned = pipeline.handle_missing_data(train_with_dates, test_with_dates)\n",
    "\n",
    "# Encode categorical values\n",
    "train_encoded, test_encoded = pipeline.encode_categorical_values(train_cleaned, test_cleaned)\n",
    "\n",
    "# Detect and handle outliers\n",
    "train_final, test_final = pipeline.detect_outliers(train_encoded, test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Columns: {'Store'}\n"
     ]
    }
   ],
   "source": [
    "common_columns = set(train_df.columns).intersection(store_df.columns)\n",
    "print(\"Common Columns:\", common_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df =store_df.drop(columns=['CompetitionDistance', 'Assortment', 'StoreType', 'Promo2', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sstore_df = store_df.rename(columns=lambda x: f\"store_{x}\" if x in common_columns else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, store_df, how='left', on='Store', suffixes=('_train', '_store'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final, test_final = pipeline.run_pipeline(\n",
    "    missing_num_strategy='mean', \n",
    "    missing_cat_strategy='mode', \n",
    "    outlier_method='zscore'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data\n",
    "train_final.to_csv('train_preprocessed.csv', index=False)\n",
    "test_final.to_csv('test_preprocessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-03 21:15:19,139 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:15:19,358 - INFO - Adding date features.\n",
      "2025-01-03 21:15:20,013 - INFO - Handling missing data\n",
      "2025-01-03 21:15:20,232 - INFO - Missing values per column:\n",
      "Store                        0.000000\n",
      "DayOfWeek                    0.000000\n",
      "Date                         0.000000\n",
      "Sales                        0.000000\n",
      "Customers                    0.000000\n",
      "Open                         0.000000\n",
      "Promo                        0.000000\n",
      "SchoolHoliday                0.000000\n",
      "StoreType                    0.000000\n",
      "Assortment                   0.000000\n",
      "CompetitionDistance          0.002597\n",
      "CompetitionOpenSinceMonth    0.317878\n",
      "CompetitionOpenSinceYear     0.317878\n",
      "Promo2                       0.000000\n",
      "Promo2SinceWeek              0.499436\n",
      "Promo2SinceYear              0.499436\n",
      "PromoInterval                0.499436\n",
      "Weekday                      0.000000\n",
      "IsWeekend                    0.000000\n",
      "Day                          0.000000\n",
      "Month                        0.000000\n",
      "Year                         0.000000\n",
      "IsHoliday                    0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:15:20,233 - INFO - Columns to drop (missing fraction > 0.49): ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:15:20,282 - INFO - Columns dropped: ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:15:21,246 - INFO - Missing values per column:\n",
      "Id                           0.000000\n",
      "Store                        0.000000\n",
      "DayOfWeek                    0.000000\n",
      "Date                         0.000000\n",
      "Open                         0.000268\n",
      "Promo                        0.000000\n",
      "SchoolHoliday                0.000000\n",
      "StoreType                    0.000000\n",
      "Assortment                   0.000000\n",
      "CompetitionDistance          0.002336\n",
      "CompetitionOpenSinceMonth    0.370327\n",
      "CompetitionOpenSinceYear     0.370327\n",
      "Promo2                       0.000000\n",
      "Promo2SinceWeek              0.419393\n",
      "Promo2SinceYear              0.419393\n",
      "PromoInterval                0.419393\n",
      "Weekday                      0.000000\n",
      "IsWeekend                    0.000000\n",
      "Day                          0.000000\n",
      "Month                        0.000000\n",
      "Year                         0.000000\n",
      "IsHoliday                    0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:15:21,246 - INFO - Columns to drop (missing fraction > 0.49): []\n",
      "2025-01-03 21:15:21,246 - INFO - No columns dropped due to missing values exceeding threshold.\n",
      "2025-01-03 21:15:21,276 - INFO - Encoding categorical values using onehot method.\n",
      "2025-01-03 21:15:21,529 - INFO - Detecting and handling outliers.\n",
      "2025-01-03 21:15:50,765 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:15:50,765 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:15:50,766 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:15:51,103 - INFO - Adding date features.\n",
      "2025-01-03 21:16:16,943 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:16:17,197 - INFO - Adding date features.\n",
      "2025-01-03 21:16:17,897 - INFO - Handling missing data\n",
      "2025-01-03 21:16:18,088 - INFO - Missing values per column:\n",
      "Store                        0.000000\n",
      "DayOfWeek                    0.000000\n",
      "Date                         0.000000\n",
      "Sales                        0.000000\n",
      "Customers                    0.000000\n",
      "Open                         0.000000\n",
      "Promo                        0.000000\n",
      "SchoolHoliday                0.000000\n",
      "StoreType                    0.000000\n",
      "Assortment                   0.000000\n",
      "CompetitionDistance          0.002597\n",
      "CompetitionOpenSinceMonth    0.317878\n",
      "CompetitionOpenSinceYear     0.317878\n",
      "Promo2                       0.000000\n",
      "Promo2SinceWeek              0.499436\n",
      "Promo2SinceYear              0.499436\n",
      "PromoInterval                0.499436\n",
      "Weekday                      0.000000\n",
      "IsWeekend                    0.000000\n",
      "Day                          0.000000\n",
      "Month                        0.000000\n",
      "Year                         0.000000\n",
      "IsHoliday                    0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:16:18,088 - INFO - Columns to drop (missing fraction > 0.49): ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:16:18,137 - INFO - Columns dropped: ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:16:19,105 - INFO - Missing values per column:\n",
      "Id                           0.000000\n",
      "Store                        0.000000\n",
      "DayOfWeek                    0.000000\n",
      "Date                         0.000000\n",
      "Open                         0.000268\n",
      "Promo                        0.000000\n",
      "SchoolHoliday                0.000000\n",
      "StoreType                    0.000000\n",
      "Assortment                   0.000000\n",
      "CompetitionDistance          0.002336\n",
      "CompetitionOpenSinceMonth    0.370327\n",
      "CompetitionOpenSinceYear     0.370327\n",
      "Promo2                       0.000000\n",
      "Promo2SinceWeek              0.419393\n",
      "Promo2SinceYear              0.419393\n",
      "PromoInterval                0.419393\n",
      "Weekday                      0.000000\n",
      "IsWeekend                    0.000000\n",
      "Day                          0.000000\n",
      "Month                        0.000000\n",
      "Year                         0.000000\n",
      "IsHoliday                    0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:16:19,106 - INFO - Columns to drop (missing fraction > 0.49): []\n",
      "2025-01-03 21:16:19,106 - INFO - No columns dropped due to missing values exceeding threshold.\n",
      "2025-01-03 21:16:19,144 - INFO - Encoding categorical values using onehot method.\n",
      "2025-01-03 21:16:19,743 - INFO - Detecting and handling outliers.\n",
      "2025-01-03 21:16:21,049 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:16:21,049 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:16:21,050 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:16:21,517 - INFO - Adding date features.\n",
      "2025-01-03 21:16:34,405 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:16:34,405 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:16:34,405 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:16:35,089 - INFO - Adding date features.\n",
      "2025-01-03 21:18:22,902 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:18:22,902 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:18:22,902 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:21:37,942 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:21:38,089 - INFO - Adding date features.\n",
      "2025-01-03 21:21:38,560 - INFO - Handling missing data\n",
      "2025-01-03 21:21:38,602 - INFO - Missing values per column:\n",
      "Store              0.000000\n",
      "DayOfWeek          0.000000\n",
      "Date               0.000000\n",
      "Sales              0.000000\n",
      "Customers          0.000000\n",
      "Open               0.000000\n",
      "Promo              0.000000\n",
      "SchoolHoliday      0.000000\n",
      "Promo2SinceWeek    0.499436\n",
      "Promo2SinceYear    0.499436\n",
      "PromoInterval      0.499436\n",
      "Weekday            0.000000\n",
      "IsWeekend          0.000000\n",
      "Day                0.000000\n",
      "Month              0.000000\n",
      "Year               0.000000\n",
      "IsHoliday          0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:21:38,602 - INFO - Columns to drop (missing fraction > 0.49): ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:21:38,631 - INFO - Columns dropped: ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:21:39,040 - INFO - Missing values per column:\n",
      "Id                 0.000000\n",
      "Store              0.000000\n",
      "DayOfWeek          0.000000\n",
      "Date               0.000000\n",
      "Open               0.000268\n",
      "Promo              0.000000\n",
      "SchoolHoliday      0.000000\n",
      "Promo2SinceWeek    0.419393\n",
      "Promo2SinceYear    0.419393\n",
      "PromoInterval      0.419393\n",
      "Weekday            0.000000\n",
      "IsWeekend          0.000000\n",
      "Day                0.000000\n",
      "Month              0.000000\n",
      "Year               0.000000\n",
      "IsHoliday          0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:21:39,041 - INFO - Columns to drop (missing fraction > 0.49): []\n",
      "2025-01-03 21:21:39,041 - INFO - No columns dropped due to missing values exceeding threshold.\n",
      "2025-01-03 21:21:39,088 - INFO - Encoding categorical values using onehot method.\n",
      "2025-01-03 21:21:39,400 - INFO - Detecting and handling outliers.\n",
      "2025-01-03 21:21:39,798 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:21:39,799 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:21:39,799 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:21:39,965 - INFO - Adding date features.\n",
      "2025-01-03 21:22:57,938 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:22:57,938 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:22:57,938 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:22:58,163 - INFO - Adding date features.\n",
      "2025-01-03 21:25:51,009 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:25:51,010 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:25:51,010 - INFO - Merging store data with train and test datasets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read and print the log file\n",
    "with open('preprocessing.log', 'r') as log_file:\n",
    "    print(log_file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
