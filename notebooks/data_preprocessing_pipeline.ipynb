{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append the parent directory to sys.path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# ignore warrnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='preprocessing.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "from scripts.Data_preprocessing_pipeline import DataPreprocessingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from data_pipeline import DataPreprocessingPipeline\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='preprocessing.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading our data is in CSV format\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "store_df = pd.read_csv('../data/store.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Initialize the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline with loaded data\n",
    "pipeline = DataPreprocessingPipeline(train_df, test_df, store_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge store data\n",
    "train_merged, test_merged = pipeline.merge_store_data()\n",
    "\n",
    "# Add date features\n",
    "train_with_dates, test_with_dates = pipeline.add_date_features(train_merged, test_merged)\n",
    "\n",
    "# Handle missing data\n",
    "train_cleaned, test_cleaned = pipeline.handle_missing_data(train_with_dates, test_with_dates)\n",
    "\n",
    "# Encode categorical values\n",
    "train_encoded, test_encoded = pipeline.encode_categorical_values(train_cleaned, test_cleaned)\n",
    "\n",
    "# Detect and handle outliers\n",
    "train_final, test_final = pipeline.detect_outliers(train_encoded, test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Columns: {'Store'}\n"
     ]
    }
   ],
   "source": [
    "common_columns = set(train_df.columns).intersection(store_df.columns)\n",
    "print(\"Common Columns:\", common_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df =store_df.drop(columns=['CompetitionDistance', 'Assortment', 'StoreType', 'Promo2', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sstore_df = store_df.rename(columns=lambda x: f\"store_{x}\" if x in common_columns else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, store_df, how='left', on='Store', suffixes=('_train', '_store'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'StateHoliday'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/10 acadamy/week-4/Rossmann--Sales-Prediction/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'StateHoliday'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_final, test_final \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing_num_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing_cat_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutlier_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/10 acadamy/week-4/Rossmann--Sales-Prediction/scripts/Data_preprocessing_pipeline.py:177\u001b[0m, in \u001b[0;36mDataPreprocessingPipeline.run_pipeline\u001b[0;34m(self, missing_num_strategy, missing_cat_strategy, outlier_method)\u001b[0m\n\u001b[1;32m    174\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning the complete preprocessing pipeline.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Preprocess datasets\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Handle missing data\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_missing_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_df, num_strategy\u001b[38;5;241m=\u001b[39mmissing_num_strategy, cat_strategy\u001b[38;5;241m=\u001b[39mmissing_cat_strategy)\n",
      "File \u001b[0;32m~/10 acadamy/week-4/Rossmann--Sales-Prediction/scripts/Data_preprocessing_pipeline.py:66\u001b[0m, in \u001b[0;36mDataPreprocessingPipeline.preprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_store_data()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Add date features\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_date_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_df\n",
      "File \u001b[0;32m~/10 acadamy/week-4/Rossmann--Sales-Prediction/scripts/Data_preprocessing_pipeline.py:52\u001b[0m, in \u001b[0;36mDataPreprocessingPipeline.add_date_features\u001b[0;34m(self, train_df, test_df)\u001b[0m\n\u001b[1;32m     49\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Use the stateHoliday feature directly to indicate holidays\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIsHoliday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStateHoliday\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Drop StateHoliday column since it's no longer needed\u001b[39;00m\n\u001b[1;32m     55\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStateHoliday\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/10 acadamy/week-4/Rossmann--Sales-Prediction/myenv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/10 acadamy/week-4/Rossmann--Sales-Prediction/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'StateHoliday'"
     ]
    }
   ],
   "source": [
    "train_final, test_final = pipeline.run_pipeline(\n",
    "    missing_num_strategy='mean',\n",
    "    missing_cat_strategy='mode',\n",
    "    outlier_method='zscore'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data\n",
    "train_final.to_csv('train_preprocessed.csv', index=False)\n",
    "test_final.to_csv('test_preprocessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-03 21:15:19,139 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:15:19,358 - INFO - Adding date features.\n",
      "2025-01-03 21:15:20,013 - INFO - Handling missing data\n",
      "2025-01-03 21:15:20,232 - INFO - Missing values per column:\n",
      "Store                        0.000000\n",
      "DayOfWeek                    0.000000\n",
      "Date                         0.000000\n",
      "Sales                        0.000000\n",
      "Customers                    0.000000\n",
      "Open                         0.000000\n",
      "Promo                        0.000000\n",
      "SchoolHoliday                0.000000\n",
      "StoreType                    0.000000\n",
      "Assortment                   0.000000\n",
      "CompetitionDistance          0.002597\n",
      "CompetitionOpenSinceMonth    0.317878\n",
      "CompetitionOpenSinceYear     0.317878\n",
      "Promo2                       0.000000\n",
      "Promo2SinceWeek              0.499436\n",
      "Promo2SinceYear              0.499436\n",
      "PromoInterval                0.499436\n",
      "Weekday                      0.000000\n",
      "IsWeekend                    0.000000\n",
      "Day                          0.000000\n",
      "Month                        0.000000\n",
      "Year                         0.000000\n",
      "IsHoliday                    0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:15:20,233 - INFO - Columns to drop (missing fraction > 0.49): ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:15:20,282 - INFO - Columns dropped: ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:15:21,246 - INFO - Missing values per column:\n",
      "Id                           0.000000\n",
      "Store                        0.000000\n",
      "DayOfWeek                    0.000000\n",
      "Date                         0.000000\n",
      "Open                         0.000268\n",
      "Promo                        0.000000\n",
      "SchoolHoliday                0.000000\n",
      "StoreType                    0.000000\n",
      "Assortment                   0.000000\n",
      "CompetitionDistance          0.002336\n",
      "CompetitionOpenSinceMonth    0.370327\n",
      "CompetitionOpenSinceYear     0.370327\n",
      "Promo2                       0.000000\n",
      "Promo2SinceWeek              0.419393\n",
      "Promo2SinceYear              0.419393\n",
      "PromoInterval                0.419393\n",
      "Weekday                      0.000000\n",
      "IsWeekend                    0.000000\n",
      "Day                          0.000000\n",
      "Month                        0.000000\n",
      "Year                         0.000000\n",
      "IsHoliday                    0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:15:21,246 - INFO - Columns to drop (missing fraction > 0.49): []\n",
      "2025-01-03 21:15:21,246 - INFO - No columns dropped due to missing values exceeding threshold.\n",
      "2025-01-03 21:15:21,276 - INFO - Encoding categorical values using onehot method.\n",
      "2025-01-03 21:15:21,529 - INFO - Detecting and handling outliers.\n",
      "2025-01-03 21:15:50,765 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:15:50,765 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:15:50,766 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:15:51,103 - INFO - Adding date features.\n",
      "2025-01-03 21:16:16,943 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:16:17,197 - INFO - Adding date features.\n",
      "2025-01-03 21:16:17,897 - INFO - Handling missing data\n",
      "2025-01-03 21:16:18,088 - INFO - Missing values per column:\n",
      "Store                        0.000000\n",
      "DayOfWeek                    0.000000\n",
      "Date                         0.000000\n",
      "Sales                        0.000000\n",
      "Customers                    0.000000\n",
      "Open                         0.000000\n",
      "Promo                        0.000000\n",
      "SchoolHoliday                0.000000\n",
      "StoreType                    0.000000\n",
      "Assortment                   0.000000\n",
      "CompetitionDistance          0.002597\n",
      "CompetitionOpenSinceMonth    0.317878\n",
      "CompetitionOpenSinceYear     0.317878\n",
      "Promo2                       0.000000\n",
      "Promo2SinceWeek              0.499436\n",
      "Promo2SinceYear              0.499436\n",
      "PromoInterval                0.499436\n",
      "Weekday                      0.000000\n",
      "IsWeekend                    0.000000\n",
      "Day                          0.000000\n",
      "Month                        0.000000\n",
      "Year                         0.000000\n",
      "IsHoliday                    0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:16:18,088 - INFO - Columns to drop (missing fraction > 0.49): ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:16:18,137 - INFO - Columns dropped: ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:16:19,105 - INFO - Missing values per column:\n",
      "Id                           0.000000\n",
      "Store                        0.000000\n",
      "DayOfWeek                    0.000000\n",
      "Date                         0.000000\n",
      "Open                         0.000268\n",
      "Promo                        0.000000\n",
      "SchoolHoliday                0.000000\n",
      "StoreType                    0.000000\n",
      "Assortment                   0.000000\n",
      "CompetitionDistance          0.002336\n",
      "CompetitionOpenSinceMonth    0.370327\n",
      "CompetitionOpenSinceYear     0.370327\n",
      "Promo2                       0.000000\n",
      "Promo2SinceWeek              0.419393\n",
      "Promo2SinceYear              0.419393\n",
      "PromoInterval                0.419393\n",
      "Weekday                      0.000000\n",
      "IsWeekend                    0.000000\n",
      "Day                          0.000000\n",
      "Month                        0.000000\n",
      "Year                         0.000000\n",
      "IsHoliday                    0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:16:19,106 - INFO - Columns to drop (missing fraction > 0.49): []\n",
      "2025-01-03 21:16:19,106 - INFO - No columns dropped due to missing values exceeding threshold.\n",
      "2025-01-03 21:16:19,144 - INFO - Encoding categorical values using onehot method.\n",
      "2025-01-03 21:16:19,743 - INFO - Detecting and handling outliers.\n",
      "2025-01-03 21:16:21,049 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:16:21,049 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:16:21,050 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:16:21,517 - INFO - Adding date features.\n",
      "2025-01-03 21:16:34,405 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:16:34,405 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:16:34,405 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:16:35,089 - INFO - Adding date features.\n",
      "2025-01-03 21:18:22,902 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:18:22,902 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:18:22,902 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:21:37,942 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:21:38,089 - INFO - Adding date features.\n",
      "2025-01-03 21:21:38,560 - INFO - Handling missing data\n",
      "2025-01-03 21:21:38,602 - INFO - Missing values per column:\n",
      "Store              0.000000\n",
      "DayOfWeek          0.000000\n",
      "Date               0.000000\n",
      "Sales              0.000000\n",
      "Customers          0.000000\n",
      "Open               0.000000\n",
      "Promo              0.000000\n",
      "SchoolHoliday      0.000000\n",
      "Promo2SinceWeek    0.499436\n",
      "Promo2SinceYear    0.499436\n",
      "PromoInterval      0.499436\n",
      "Weekday            0.000000\n",
      "IsWeekend          0.000000\n",
      "Day                0.000000\n",
      "Month              0.000000\n",
      "Year               0.000000\n",
      "IsHoliday          0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:21:38,602 - INFO - Columns to drop (missing fraction > 0.49): ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:21:38,631 - INFO - Columns dropped: ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "2025-01-03 21:21:39,040 - INFO - Missing values per column:\n",
      "Id                 0.000000\n",
      "Store              0.000000\n",
      "DayOfWeek          0.000000\n",
      "Date               0.000000\n",
      "Open               0.000268\n",
      "Promo              0.000000\n",
      "SchoolHoliday      0.000000\n",
      "Promo2SinceWeek    0.419393\n",
      "Promo2SinceYear    0.419393\n",
      "PromoInterval      0.419393\n",
      "Weekday            0.000000\n",
      "IsWeekend          0.000000\n",
      "Day                0.000000\n",
      "Month              0.000000\n",
      "Year               0.000000\n",
      "IsHoliday          0.000000\n",
      "dtype: float64\n",
      "2025-01-03 21:21:39,041 - INFO - Columns to drop (missing fraction > 0.49): []\n",
      "2025-01-03 21:21:39,041 - INFO - No columns dropped due to missing values exceeding threshold.\n",
      "2025-01-03 21:21:39,088 - INFO - Encoding categorical values using onehot method.\n",
      "2025-01-03 21:21:39,400 - INFO - Detecting and handling outliers.\n",
      "2025-01-03 21:21:39,798 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:21:39,799 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:21:39,799 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:21:39,965 - INFO - Adding date features.\n",
      "2025-01-03 21:22:57,938 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:22:57,938 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:22:57,938 - INFO - Merging store data with train and test datasets.\n",
      "2025-01-03 21:22:58,163 - INFO - Adding date features.\n",
      "2025-01-03 21:25:51,009 - INFO - Running the complete preprocessing pipeline.\n",
      "2025-01-03 21:25:51,010 - INFO - Running preprocessing on both train and test datasets.\n",
      "2025-01-03 21:25:51,010 - INFO - Merging store data with train and test datasets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read and print the log file\n",
    "with open('preprocessing.log', 'r') as log_file:\n",
    "    print(log_file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
